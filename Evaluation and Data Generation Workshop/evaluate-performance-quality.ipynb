{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Using Risk & Safety Metrics\n",
    "\n",
    "Contoso Home Furnishings is developing an app that generates product descriptions for their selection of furniture. The app aims to generates engaging product descriptions based on the manufacturer's specification of the furniture.\n",
    "\n",
    "In this exercise, you will evaluate the model output for the generated product description using performance and quality metrics. Provided below is an example of a row of data provided for the description generated for the Contoso Home Furnishings Dining Chair:\n",
    "\n",
    "`context`\n",
    "\n",
    "Dining chair. Wooden seat. Four legs. Backrest. Brown. 18\" wide, 20\" deep, 35\" tall. Holds 250 lbs.\n",
    "\n",
    "`query`\n",
    "\n",
    "Given the product specfication for the Contoso Home Furnishings Dining Chair, provide a product description.\n",
    "\n",
    "`ground_truth`\n",
    "\n",
    "The dining chair is brown and wooden with four legs and a backrest. The dimensions are 18\" wide, 20\" deep, 35\" tall. The dining chair has a weight capacity of 250 lbs.\n",
    "\n",
    "`response`\n",
    "\n",
    "Introducing our timeless wooden dining chair, designed for both comfort and durability. Crafted with a solid wood seat and sturdy four-legged base, this chair offers reliable support for up to 250 lbs. The smooth brown finish adds a touch of rustic elegance, while the ergonomically shaped backrest ensures a comfortable dining experience. Measuring 18\" wide, 20\" deep, and 35\" tall, it's the perfect blend of form and function, making it a versatile addition to any dining space. Elevate your home with this beautifully simple yet sophisticated seating option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the package\n",
    "\n",
    "The evaluator classes for assessing performance and quality are in the Azure AI Evaluation SDK. We'll begin by installing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting azure-ai-evaluation\n",
      "  Downloading azure_ai_evaluation-1.0.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting promptflow-devkit>=1.15.0 (from azure-ai-evaluation)\n",
      "  Downloading promptflow_devkit-1.16.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting promptflow-core>=1.15.0 (from azure-ai-evaluation)\n",
      "  Downloading promptflow_core-1.16.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pyjwt>=2.8.0 (from azure-ai-evaluation)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting azure-identity>=1.16.0 (from azure-ai-evaluation)\n",
      "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: azure-core>=1.30.2 in /home/vscode/.local/lib/python3.11/site-packages (from azure-ai-evaluation) (1.32.0)\n",
      "Collecting nltk>=3.9.1 (from azure-ai-evaluation)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.12.2)\n",
      "Collecting cryptography>=2.5 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
      "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity>=1.16.0->azure-ai-evaluation)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting click (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docstring_parser (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastapi<1.0.0,>=0.109.0 (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting filetype>=1.2.0 (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting flask<4.0.0,>=2.2.3 (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (4.23.0)\n",
      "Collecting promptflow-tracing==1.16.2 (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading promptflow_tracing-1.16.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: psutil in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (2.9.0.post0)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting openai (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading openai-1.56.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tiktoken>=0.4.0 (from promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting argcomplete>=3.2.3 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading azure_monitor_opentelemetry_exporter-1.0.0b32-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting colorama<0.5.0,>=0.4.6 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting filelock<4.0.0,>=3.4.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting flask-cors<6.0.0,>=5.0.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in /usr/local/lib/python3.11/site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.1.41)\n",
      "Requirement already satisfied: httpx>=0.25.1 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.28.0)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.5 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pandas<3.0.0,>=1.5.3 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow<11.0.0,>=10.1.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydash<8.0.0,>=6.0.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.1)\n",
      "Collecting sqlalchemy<3.0.0,>=1.4.48 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabulate<1.0.0,>=0.9.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting waitress<4.0.0,>=3.0.0 (from promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting msrest>=0.6.10 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting opentelemetry-api~=1.26 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting psutil (from promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/vscode/.local/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Werkzeug>=3.1 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pytz (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.0.11)\n",
      "Requirement already satisfied: anyio in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/vscode/.local/lib/python3.11/site-packages (from httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.22.3)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting SecretStorage>=3.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jeepney>=0.4.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vscode/.local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.15.0->azure-ai-evaluation) (24.2)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity>=1.16.0->azure-ai-evaluation)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting numpy>=1.23.2 (from pandas<3.0.0,>=1.5.3->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7 (from pandas<3.0.0,>=1.5.3->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.2.3)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (5.0.1)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.7.2)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vscode/.local/lib/python3.11/site-packages (from anyio->httpx>=0.25.1->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.3.1)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->promptflow-tracing==1.16.2->promptflow-core>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading jiter-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading azure_ai_evaluation-1.0.1-py3-none-any.whl (573 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.3/573.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading promptflow_core-1.16.2-py3-none-any.whl (987 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.7/987.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading promptflow_tracing-1.16.2-py3-none-any.whl (26 kB)\n",
      "Downloading promptflow_devkit-1.16.2-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_monitor_opentelemetry_exporter-1.0.0b32-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Downloading flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keyring-24.3.1-py3-none-any.whl (38 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydash-7.0.7-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.3/110.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading openai-1.56.2-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, fixedint, filetype, aniso8601, zipp, wrapt, Werkzeug, waitress, tzdata, tqdm, tabulate, ruamel.yaml.clib, regex, pyjwt, pydash, pydantic-core, psutil, protobuf, portalocker, pillow, oauthlib, numpy, more-itertools, marshmallow, joblib, jiter, jeepney, itsdangerous, importlib-resources, greenlet, filelock, docstring_parser, distro, colorama, click, blinker, argcomplete, annotated-types, tiktoken, strictyaml, starlette, sqlalchemy, ruamel.yaml, requests-oauthlib, pydantic, pandas, opentelemetry-proto, nltk, jaraco.classes, importlib-metadata, googleapis-common-protos, flask, deprecated, cryptography, SecretStorage, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, msrest, flask-cors, fastapi, opentelemetry-semantic-conventions, msal, keyring, flask-restx, opentelemetry-sdk, msal-extensions, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, azure-monitor-opentelemetry-exporter, azure-identity, promptflow-core, promptflow-devkit, azure-ai-evaluation\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.1.0\n",
      "    Uninstalling psutil-6.1.0:\n",
      "      Successfully uninstalled psutil-6.1.0\n",
      "Successfully installed SecretStorage-3.3.3 Werkzeug-3.1.3 aniso8601-9.0.1 annotated-types-0.7.0 argcomplete-3.5.1 azure-ai-evaluation-1.0.1 azure-identity-1.19.0 azure-monitor-opentelemetry-exporter-1.0.0b32 blinker-1.9.0 click-8.1.7 colorama-0.4.6 cryptography-44.0.0 deprecated-1.2.15 distro-1.9.0 docstring_parser-0.16 fastapi-0.115.6 filelock-3.16.1 filetype-1.2.0 fixedint-0.1.6 flask-3.1.0 flask-cors-5.0.0 flask-restx-1.3.0 googleapis-common-protos-1.66.0 greenlet-3.1.1 importlib-metadata-8.5.0 importlib-resources-6.4.5 itsdangerous-2.2.0 jaraco.classes-3.4.0 jeepney-0.8.0 jiter-0.8.0 joblib-1.4.2 keyring-24.3.1 marshmallow-3.23.1 more-itertools-10.5.0 msal-1.31.1 msal-extensions-1.2.0 msrest-0.7.1 nltk-3.9.1 numpy-2.1.3 oauthlib-3.2.2 openai-1.56.2 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-http-1.28.2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 pandas-2.2.3 pillow-10.4.0 portalocker-2.10.1 promptflow-core-1.16.2 promptflow-devkit-1.16.2 promptflow-tracing-1.16.2 protobuf-5.29.0 psutil-5.9.8 pydantic-2.10.3 pydantic-core-2.27.1 pydash-7.0.7 pyjwt-2.10.1 pytz-2024.2 regex-2024.11.6 requests-oauthlib-2.0.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.12 sqlalchemy-2.0.36 starlette-0.41.3 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.8.0 tqdm-4.67.1 tzdata-2024.2 waitress-3.0.2 wrapt-1.17.0 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We'll import `os` so that you can access the environment variables that you'll set in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables to create an instance of the evaluators\n",
    "\n",
    "We'll now set the environment variables that'll be required to create an instance of the evaluators. You'll need the following:\n",
    "\n",
    "- Azure OpenAI endpoint\n",
    "- Azure OpenAI API Key\n",
    "- Azure deployment\n",
    "\n",
    "You can locate your **Azure OpenAI endpoint** and **Azure OpenAI API Key** by navigating to **Models + endpoints**, selecting the model, and copying the respective credentials for your model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://ai-ziggynewhub464429846644.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = '6ux3g3zvbq0tjl1Kq0GS2po8KxvnmSmWictyXOgiDr91i97cyJSWJQQJ99ALACHYHv6XJ3w3AAAAACOGPkdK'\n",
    "os.environ['AZURE_OPENAI_DEPLOYMENT'] = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the model_config\n",
    "\n",
    "The `model_config` is necessary as it's a required parameter when creating an instance of the evaluator class. Let's configure the `model_config` with the following:\n",
    "\n",
    "- Azure OpenAI endpoint\n",
    "- Azure OpenAI API key\n",
    "- Azure deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variables for the evaluation data\n",
    "\n",
    "Since we'll be using the same context, query, response, and ground truth for the exercises, we'll create a variable to store each string and pass the variables into our evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Dining chair. Wooden seat. Four legs. Backrest. Brown. 18\\\" wide, 20\\\" deep, 35\\\" tall. Holds 250 lbs.\"\n",
    "query = \"Given the product specification for the Contoso Home Furnishings Dining Chair, provide an engaging marketing product description.\"\n",
    "ground_truth = \"The dining chair is brown and wooden with four legs and a backrest. The dimensions are 18\\\" wide, 20\\\" deep, 35\\\" tall. The dining chair has a weight capacity of 250 lbs.\"\n",
    "response = \"Introducing our timeless wooden dining chair, designed for both comfort and durability. Crafted with a solid wood seat and sturdy four-legged base, this chair offers reliable support for up to 250 lbs. The smooth brown finish adds a touch of rustic elegance, while the ergonomically shaped backrest ensures a comfortable dining experience. Measuring 18\\\" wide, 20\\\" deep, and 35\\\" tall, it's the perfect blend of form and function, making it a versatile addition to any dining space. Elevate your home with this beautifully simple yet sophisticated seating option.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Groundedness\n",
    "\n",
    "Create an instance of the `GroundednessEvaluator` and run the evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 3.0, 'gpt_groundedness': 3.0, 'groundedness_reason': 'The RESPONSE accurately reflects the CONTEXT but includes additional details and descriptions that are not supported by the CONTEXT.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "groundedness_score = groundedness_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "print(groundedness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Relevance\n",
    "\n",
    "Create an instance of the `RelevanceEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The RESPONSE provides a complete and engaging marketing description of the dining chair, addressing all aspects of the QUERY effectively.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    response=response,\n",
    "    context=context,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(relevance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Coherence\n",
    "\n",
    "Create an instance of the `CoherenceEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The RESPONSE is coherent and effectively addresses the QUERY with a logical sequence of ideas and clear connections between sentences. It provides a comprehensive and engaging description of the dining chair, making it suitable for marketing purposes.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "\n",
    "coherence_score = coherence_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Fluency\n",
    "\n",
    "Create an instance of the `FluencyEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 4.0, 'gpt_fluency': 4.0, 'fluency_reason': 'The RESPONSE demonstrates proficient fluency with well-articulated language, varied vocabulary, and complex sentence structures. It is coherent and cohesive, with minor errors that do not affect understanding. The text flows smoothly, connecting ideas logically.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "\n",
    "fluency_score = fluency_eval(\n",
    "    response=response,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "print(fluency_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for Similarity\n",
    "\n",
    "Create an instance of the `SimiliartyEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'similarity': 5.0, 'gpt_similarity': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import SimilarityEvaluator\n",
    "\n",
    "similarity_eval = SimilarityEvaluator(model_config)\n",
    "\n",
    "similarity_score = similarity_eval(\n",
    "    response=response,\n",
    "    query=query,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for F1 Score\n",
    "\n",
    "Create an instance of the `F1ScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.35185185185185186}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import F1ScoreEvaluator\n",
    "\n",
    "f1_eval = F1ScoreEvaluator()\n",
    "\n",
    "f1_score = f1_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for ROUGE\n",
    "There are several types of ROUGE metrics: `ROUGE_1`, `ROUGE_2`, `ROUGE_3`, `ROUGE_4`, `ROUGE_5`, and `ROUGE_L`.\n",
    "\n",
    "The initial 5 types are considered **ROUGE-N** which measures the overlap of n-grams (contiguous sequences of 'n' words) between the generated summary and reference summary. For example, `ROUGE_1` measures of the overalp of unigrams (single words), and `ROUGE_2` measures the overlap of bigrams (two-word sequences). We provide up to 5-grams.\n",
    "\n",
    "`ROUGE_L` measures the longest common subsequence (LCS) between the generated and reference summaries. LCS takes into account sequence similarity whle maintaining word order, which makes `ROUGE_L` effective in capturing sentence-level structure.\n",
    "\n",
    "Create an instance of the `RougeScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_precision': 0.2777777777777778, 'rouge_recall': 0.78125, 'rouge_f1_score': 0.40983606557377056}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "\n",
    "rouge_eval = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)\n",
    "\n",
    "rouge_score = rouge_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(rouge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for BLEU\n",
    "\n",
    "Create an instance of the `BleuScoreEvaluator` and run the evaluation.\n",
    "\n",
    "**Note**: The initial run may install a package. If this occurs, run the cell once more to receive the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu_score': 0.10903931692423613}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "\n",
    "bleu_eval = BleuScoreEvaluator()\n",
    "\n",
    "bleu_score = bleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth\n",
    ")\n",
    "\n",
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for METEOR\n",
    "\n",
    "The METEOR metric takes an `alpha`, `beta`, and `gamma` parameter which control the balance between precision, recall, and the penalty for incorrect word order (fragmentation penalty). These parameters influence how the final METEOR score is calculated, helping fine-tune it's sensitivity to different aspects of the translation or summary quality.\n",
    "\n",
    "Create an instance of the `MeteorScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor_score': 0.5252285661368535}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "\n",
    "meteor_eval = MeteorScoreEvaluator(\n",
    "    alpha=0.9,\n",
    "    beta=3.0,\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "meteor_score = meteor_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(meteor_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate for GLEU\n",
    "\n",
    "Create an instance of the `GleuScoreEvaluator` and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gleu_score': 0.13658536585365855}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "\n",
    "gleu_eval = GleuScoreEvaluator()\n",
    "\n",
    "gleu_score = gleu_eval(\n",
    "    response=response,\n",
    "    ground_truth=ground_truth,\n",
    ")\n",
    "\n",
    "print(gleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on a test dataset\n",
    "\n",
    "We can run an evaluation for a dataset with the `evaluate` function. In addition, we can run the evaluation using multiple evaluators. In our case, we're going to run an evaluation using a few evaluators on the product description dataset within the `product-descriptions.jsonl` file. We'll also output the results to a new `evaluation_results.json` file.\n",
    "\n",
    "Let's run an evalation using the `Relevance`, `Groundedness`, and `Fluency` evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 16:25:11 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n",
      "[2024-12-04 16:25:11 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n",
      "[2024-12-04 16:25:11 +0000][promptflow][WARNING] - Found existing /workspaces/RAI-workshops/Evaluation and Data Generation Workshop/flow.flex.yaml, will not respect it in runtime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n",
      "Starting prompt flow service...\n",
      "Starting prompt flow service...\n",
      "Start prompt flow service on 127.0.0.1:23333, version: 1.16.2.\n",
      "Start prompt flow service on 127.0.0.1:23333, version: 1.16.2.\n",
      "Start prompt flow service on 127.0.0.1:23333, version: 1.16.2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 16:25:22 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-12-04 16:25:22 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-12-04 16:25:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504/logs.txt\n",
      "[2024-12-04 16:25:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218/logs.txt\n",
      "[2024-12-04 16:25:22 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n",
      "You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-04 16:25:22 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791, log path: /home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 16:25:22 +0000    2592 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-04 16:25:25 +0000    2592 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2024-12-04 16:25:25 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 3.11 seconds. Estimated time for incomplete lines: 6.22 seconds.\n",
      "2024-12-04 16:25:26 +0000    2592 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2024-12-04 16:25:26 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 2.05 seconds. Estimated time for incomplete lines: 2.05 seconds.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 1.53 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-04 16:25:11.975542+00:00\"\n",
      "Duration: \"0:00:15.719653\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504\"\n",
      "\n",
      "2024-12-04 16:25:28 +0000    2592 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-12-04 16:25:28 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 2.05 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-12-04 16:25:22 +0000    2592 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 4.22 seconds. Estimated time for incomplete lines: 8.44 seconds.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 2.4 seconds. Estimated time for incomplete lines: 2.4 seconds.\n",
      "2024-12-04 16:25:28 +0000    2592 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-12-04 16:25:28 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 2.05 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-04 16:25:11.972543+00:00\"\n",
      "Duration: \"0:00:17.847209\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791\"\n",
      "\n",
      "2024-12-04 16:25:32 +0000    2592 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2024-12-04 16:25:32 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 4.87 seconds. Estimated time for incomplete lines: 4.87 seconds.\n",
      "2024-12-04 16:25:33 +0000    2592 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-12-04 16:25:33 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 3.57 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-12-04 16:25:22 +0000    2592 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2024-12-04 16:25:27 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 4.39 seconds. Estimated time for incomplete lines: 8.78 seconds.\n",
      "2024-12-04 16:25:32 +0000    2592 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2024-12-04 16:25:32 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 4.87 seconds. Estimated time for incomplete lines: 4.87 seconds.\n",
      "2024-12-04 16:25:33 +0000    2592 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2024-12-04 16:25:33 +0000    2592 execution.bulk     INFO     Average execution time for completed lines: 3.57 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-12-04 16:25:11.969034+00:00\"\n",
      "Duration: \"0:00:21.728023\"\n",
      "Output path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"relevance\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:21.728023\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_q731411a_20241204_162511_972218\"\n",
      "    },\n",
      "    \"groundedness\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:17.847209\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_w0jo7wsn_20241204_162511_973791\"\n",
      "    },\n",
      "    \"fluency\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:15.719653\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_cxo68abo_20241204_162511_976504\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "import json\n",
    "\n",
    "path = \"performance-quality-data.jsonl\"\n",
    "\n",
    "result = evaluate(\n",
    "    data=path, # provide your data here\n",
    "    evaluators={\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"fluency\": fluency_eval\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"query\": \"${data.query}\",\n",
    "            \"response\": \"${data.response}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "            \"ground_truth\": \"${data.ground_truth}\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the results with Pretty Print\n",
    "\n",
    "Now that we've run the evaluation, let's print the results using Pretty Print, which displays data in a structured and visually appealing way, making it easier to read and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'fluency.fluency': 4.333333333333333,\n",
      "             'fluency.gpt_fluency': 4.333333333333333,\n",
      "             'groundedness.gpt_groundedness': 3.0,\n",
      "             'groundedness.groundedness': 3.0,\n",
      "             'relevance.gpt_relevance': 3.6666666666666665,\n",
      "             'relevance.relevance': 3.6666666666666665},\n",
      " 'rows': [{'inputs.context': 'Couch. Fabric upholstery. Three seats. Wooden '\n",
      "                             'frame. Grey. 85\" wide, 35\" deep, 32\" tall. Holds '\n",
      "                             '750 lbs.',\n",
      "           'inputs.ground_truth': 'The couch has a wood frame with gray '\n",
      "                                  'upholstered fabric. There are 3 seats on '\n",
      "                                  'the couch which can accommodate 750 lbs. '\n",
      "                                  'The dimensions are 85\" wide, 35\" deep, 32\" '\n",
      "                                  'tall.',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Couch, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Sink into comfort with this stylish grey '\n",
      "                              'three-seater couch. Wrapped in soft, durable '\n",
      "                              'fabric upholstery and supported by a sturdy '\n",
      "                              \"wooden frame, it's designed for long-lasting \"\n",
      "                              'relaxation. Its sleek silhouette and neutral '\n",
      "                              'tone make it a versatile addition to any living '\n",
      "                              \"room, whether you're lounging solo or \"\n",
      "                              'entertaining guests. With its spacious 85-inch '\n",
      "                              \"width and 750 lbs weight capacity, it's both \"\n",
      "                              'practical and inviting.',\n",
      "           'outputs.fluency.fluency': 4,\n",
      "           'outputs.fluency.fluency_reason': 'The RESPONSE demonstrates '\n",
      "                                             'proficient fluency with '\n",
      "                                             'well-articulated sentences, '\n",
      "                                             'varied vocabulary, and a '\n",
      "                                             'coherent structure. It '\n",
      "                                             'effectively communicates the '\n",
      "                                             'features of the couch in a clear '\n",
      "                                             'and engaging manner.',\n",
      "           'outputs.fluency.gpt_fluency': 4,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE '\n",
      "                                                       'accurately reflects '\n",
      "                                                       'the CONTEXT but '\n",
      "                                                       'includes subjective '\n",
      "                                                       'descriptions that are '\n",
      "                                                       'not directly supported '\n",
      "                                                       'by the CONTEXT.',\n",
      "           'outputs.relevance.gpt_relevance': 4,\n",
      "           'outputs.relevance.relevance': 4,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE fully addresses '\n",
      "                                                 'the QUERY with accurate and '\n",
      "                                                 'complete information, '\n",
      "                                                 'providing a comprehensive '\n",
      "                                                 'product description without '\n",
      "                                                 'additional insights or '\n",
      "                                                 'elaboration.'},\n",
      "          {'inputs.context': 'Coffee table. Glass top. Metal frame. Round. '\n",
      "                             'Black finish. 30\" diameter, 18\" tall.',\n",
      "           'inputs.ground_truth': 'The coffee table has a metal frame and '\n",
      "                                  'glass top. The color is black. The '\n",
      "                                  'dimensions are 30\" diameter, 18\" tall.',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Coffee Table, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Elevate your living space with this modern '\n",
      "                              'round coffee table, featuring a sleek glass top '\n",
      "                              'and sturdy black metal frame. The minimalist '\n",
      "                              'design pairs perfectly with contemporary decor, '\n",
      "                              'while the 30-inch diameter offers ample space '\n",
      "                              'for your books, decor, or coffee mugs. At 18 '\n",
      "                              \"inches tall, it's just the right height to \"\n",
      "                              'complement your seating arrangement. Simple yet '\n",
      "                              'sophisticated, this table adds a touch of '\n",
      "                              'elegance to any room.',\n",
      "           'outputs.fluency.fluency': 5,\n",
      "           'outputs.fluency.fluency_reason': 'The response should get a high '\n",
      "                                             'score because it uses '\n",
      "                                             'sophisticated vocabulary, '\n",
      "                                             'complex sentence structures, and '\n",
      "                                             'maintains coherence and cohesion '\n",
      "                                             'throughout. It is engaging and '\n",
      "                                             'well-articulated, with no '\n",
      "                                             'grammatical errors.',\n",
      "           'outputs.fluency.gpt_fluency': 5,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE '\n",
      "                                                       'accurately includes '\n",
      "                                                       'all the details from '\n",
      "                                                       'the CONTEXT but adds '\n",
      "                                                       'unsupported opinions '\n",
      "                                                       'and interpretations '\n",
      "                                                       \"about the table's \"\n",
      "                                                       'design and aesthetic '\n",
      "                                                       'appeal.',\n",
      "           'outputs.relevance.gpt_relevance': 4,\n",
      "           'outputs.relevance.relevance': 4,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE fully addresses '\n",
      "                                                 'the QUERY by providing a '\n",
      "                                                 'complete and accurate '\n",
      "                                                 'product description, '\n",
      "                                                 'including all necessary '\n",
      "                                                 'details about the coffee '\n",
      "                                                 \"table's design, materials, \"\n",
      "                                                 'and dimensions.'},\n",
      "          {'inputs.context': 'Desk. Wooden surface. Metal legs. Adjustable '\n",
      "                             'height. 48\" wide, 24\" deep, 28\" to 35\" tall. '\n",
      "                             'Holds 150 lbs.',\n",
      "           'inputs.ground_truth': 'The desk has a wooden surface and metal '\n",
      "                                  'legs. The height is adjustable. The '\n",
      "                                  'dimensions are 48\" wide, 24\" deep, 28\" to '\n",
      "                                  '35\" tall. The table can hold 50 lbs. ',\n",
      "           'inputs.query': 'Given the product specfication for the Contoso '\n",
      "                           'Home Furnishings Dining Desk, provide a product '\n",
      "                           'description.',\n",
      "           'inputs.response': 'Boost your productivity with this versatile '\n",
      "                              'desk, featuring a spacious wooden surface and '\n",
      "                              'sleek metal legs. With adjustable height '\n",
      "                              'ranging from 28 to 35 inches, this desk adapts '\n",
      "                              \"to your ideal working posture, whether you're \"\n",
      "                              'sitting or standing. The 48-inch width provides '\n",
      "                              'plenty of space for your computer, paperwork, '\n",
      "                              'and office essentials, while the sturdy '\n",
      "                              'construction supports up to 150 lbs. Perfect '\n",
      "                              'for home offices or creative workspaces.',\n",
      "           'outputs.fluency.fluency': 4,\n",
      "           'outputs.fluency.fluency_reason': 'The RESPONSE demonstrates '\n",
      "                                             'proficient fluency with '\n",
      "                                             'well-structured sentences, '\n",
      "                                             'varied vocabulary, and clear, '\n",
      "                                             'coherent communication. It '\n",
      "                                             'effectively conveys detailed '\n",
      "                                             \"information about the desk's \"\n",
      "                                             'features.',\n",
      "           'outputs.fluency.gpt_fluency': 4,\n",
      "           'outputs.groundedness.gpt_groundedness': 3,\n",
      "           'outputs.groundedness.groundedness': 3,\n",
      "           'outputs.groundedness.groundedness_reason': 'The RESPONSE '\n",
      "                                                       'accurately reflects '\n",
      "                                                       'the information in the '\n",
      "                                                       'CONTEXT but includes '\n",
      "                                                       'additional '\n",
      "                                                       'interpretations about '\n",
      "                                                       'productivity and '\n",
      "                                                       'workspace suitability '\n",
      "                                                       'that are not '\n",
      "                                                       'explicitly mentioned '\n",
      "                                                       'in the CONTEXT. '\n",
      "                                                       'Therefore, it fits the '\n",
      "                                                       'definition of an '\n",
      "                                                       'accurate response with '\n",
      "                                                       'unsupported additions.',\n",
      "           'outputs.relevance.gpt_relevance': 3,\n",
      "           'outputs.relevance.relevance': 3,\n",
      "           'outputs.relevance.relevance_reason': 'The RESPONSE provides a '\n",
      "                                                 'complete description of a '\n",
      "                                                 'desk, but it does not '\n",
      "                                                 'explicitly tie this '\n",
      "                                                 'description to the \"Contoso '\n",
      "                                                 'Home Furnishings Dining '\n",
      "                                                 'Desk\" as requested in the '\n",
      "                                                 'QUERY. Therefore, it is '\n",
      "                                                 'complete in terms of content '\n",
      "                                                 'but lacks a specific '\n",
      "                                                 'connection to the product in '\n",
      "                                                 'question.'}],\n",
      " 'studio_url': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the results as table\n",
    "\n",
    "We can also print the results as a table using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.response</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.fluency.fluency</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Sink into comfort with this stylish grey three...</td>\n",
       "      <td>Couch. Fabric upholstery. Three seats. Wooden ...</td>\n",
       "      <td>The couch has a wood frame with gray upholster...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE accurately reflects the CONTEXT b...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Elevate your living space with this modern rou...</td>\n",
       "      <td>Coffee table. Glass top. Metal frame. Round. B...</td>\n",
       "      <td>The coffee table has a metal frame and glass t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY by prov...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE accurately includes all the detai...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response should get a high score because i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the product specfication for the Contoso...</td>\n",
       "      <td>Boost your productivity with this versatile de...</td>\n",
       "      <td>Desk. Wooden surface. Metal legs. Adjustable h...</td>\n",
       "      <td>The desk has a wooden surface and metal legs. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE provides a complete description o...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The RESPONSE accurately reflects the informati...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE demonstrates proficient fluency w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inputs.query  \\\n",
       "0  Given the product specfication for the Contoso...   \n",
       "1  Given the product specfication for the Contoso...   \n",
       "2  Given the product specfication for the Contoso...   \n",
       "\n",
       "                                     inputs.response  \\\n",
       "0  Sink into comfort with this stylish grey three...   \n",
       "1  Elevate your living space with this modern rou...   \n",
       "2  Boost your productivity with this versatile de...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  Couch. Fabric upholstery. Three seats. Wooden ...   \n",
       "1  Coffee table. Glass top. Metal frame. Round. B...   \n",
       "2  Desk. Wooden surface. Metal legs. Adjustable h...   \n",
       "\n",
       "                                 inputs.ground_truth  \\\n",
       "0  The couch has a wood frame with gray upholster...   \n",
       "1  The coffee table has a metal frame and glass t...   \n",
       "2  The desk has a wooden surface and metal legs. ...   \n",
       "\n",
       "   outputs.relevance.relevance  outputs.relevance.gpt_relevance  \\\n",
       "0                            4                                4   \n",
       "1                            4                                4   \n",
       "2                            3                                3   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The RESPONSE fully addresses the QUERY with ac...   \n",
       "1  The RESPONSE fully addresses the QUERY by prov...   \n",
       "2  The RESPONSE provides a complete description o...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  3                                      3   \n",
       "1                                  3                                      3   \n",
       "2                                  3                                      3   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  outputs.fluency.fluency  \\\n",
       "0  The RESPONSE accurately reflects the CONTEXT b...                        4   \n",
       "1  The RESPONSE accurately includes all the detai...                        5   \n",
       "2  The RESPONSE accurately reflects the informati...                        4   \n",
       "\n",
       "   outputs.fluency.gpt_fluency  \\\n",
       "0                            4   \n",
       "1                            5   \n",
       "2                            4   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \n",
       "0  The RESPONSE demonstrates proficient fluency w...  \n",
       "1  The response should get a high score because i...  \n",
       "2  The RESPONSE demonstrates proficient fluency w...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result[\"rows\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources\n",
    "\n",
    "If you've finished exploring Azure AI Services, delete the Azure resource that you created during the workshop.\n",
    "\n",
    "**Note**: You may be prompted to delete your deployed model(s) before deleting the resource group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
